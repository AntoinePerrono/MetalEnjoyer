{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metal enjoyer\n",
    "\n",
    "## Part 1: Data collect\n",
    "\n",
    "This code retrieves information about actors from Wikidata using a SPARQL query, downloads their images, extracts EXIF metadata and dominant colors from the images, and stores all the information in a JSON file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparqlwrapper in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from sparqlwrapper) (7.1.3)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from rdflib>=6.1.1->sparqlwrapper) (0.7.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from rdflib>=6.1.1->sparqlwrapper) (3.2.1)\n",
      "Requirement already satisfied: ipywidgets in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: decorator in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: stack_data in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: numpy in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: exifread in /home/skafee/cours/s8/DataMining/env/lib/python3.10/site-packages (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "!pip install sparqlwrapper\n",
    "!pip install ipywidgets\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install exifread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of data importing...\n",
      "All data had been imported.\n",
      "97 albums traités et sauvegardés.\n",
      "Dominant color begin ...\n",
      "Dominant color done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from time import sleep\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# User-Agent pour identifier ton projet auprès des API\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"EngineeringStudend_DataMining_Project/0.0.1 (antoine.perrono@cpe.fr)\"\n",
    "}\n",
    "\n",
    "# Définition de l'URL du point d'accès SPARQL de Wikidata\n",
    "SPARQL_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Requête SPARQL\n",
    "SPARQL_QUERY = \"\"\"\n",
    "SELECT DISTINCT ?album ?albumLabel ?image ?genreLabel ?bandLabel ?date ?nbTracks\n",
    "WHERE {\n",
    "  ?album wdt:P31 wd:Q482994;     # album\n",
    "         wdt:P136 ?genre;        # Genre musical\n",
    "         wdt:P175 ?band;\n",
    "         wdt:P577 ?date.\n",
    "  OPTIONAL { ?album wdt:P18 ?image }          # img\n",
    "  OPTIONAL { ?album wdt:P2635 ?nbTracks }     # Nombre de pistes\n",
    "  VALUES ?genre { wd:Q183862 wd:Q377910 wd:Q542703 wd:Q484344 wd:Q475221 }  # Genre \n",
    "  FILTER(YEAR(?date) > 2010)\n",
    "         \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "# Fonction pour exécuter la requête SPARQL\n",
    "def execute_sparql_query():\n",
    "    response = requests.get(SPARQL_ENDPOINT, params={\"query\": SPARQL_QUERY, \"format\": \"json\"}, headers=HEADERS)\n",
    "    response.raise_for_status()  # Vérifie si la requête a réussi\n",
    "    return response.json()\n",
    "\n",
    "def download_image(url, filename):\n",
    "    try:\n",
    "        # Télécharger l'image\n",
    "        response = requests.get(url, stream=True, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Sauvegarde de l'image\n",
    "        with open(filename, \"wb\") as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "\n",
    "        # Extraction des métadonnées EXIF\n",
    "        exif_data = extract_exif(filename)\n",
    "        \n",
    "        return filename, exif_data  # Retourne le chemin + les EXIF extraits\n",
    "\n",
    "    except requests.RequestException:\n",
    "        return None, None\n",
    "\n",
    "def extract_exif(image_path):\n",
    "    \"\"\" Extrait les métadonnées EXIF d'une image et les rend JSON-compatibles. \"\"\"\n",
    "    exif_data = {\"Favorite\": \"NotFavorite\", \"DominantColor1\": \"Undefined\"}\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        exif = image._getexif()\n",
    "        if not exif:\n",
    "            return exif_data\n",
    "        \n",
    "        for tag, value in exif.items():\n",
    "            tag_name = TAGS.get(tag, tag)  # Convertir l'ID en nom lisible\n",
    "            if tag_name == \"StripByteCounts\":\n",
    "                continue\n",
    "            \n",
    "            # Conversion des objets IFDRational en float\n",
    "            if isinstance(value, tuple):  \n",
    "                value = tuple(float(v) if isinstance(v, (int, float)) else str(v) for v in value)\n",
    "            elif isinstance(value, bytes):\n",
    "                value = value.decode(errors=\"ignore\")  # Convertir en string si possible\n",
    "            elif hasattr(value, \"numerator\") and hasattr(value, \"denominator\"):\n",
    "                value = float(value.numerator) / float(value.denominator)  # Conversion des IFDRational\n",
    "            \n",
    "            exif_data[tag_name] = value\n",
    "\n",
    "        return exif_data\n",
    "\n",
    "    except Exception:\n",
    "        return exif_data\n",
    "\n",
    "\n",
    "# Fonction unique pour récupérer la cover ET le nombre de pistes via MusicBrainz\n",
    "def get_musicbrainz_data(artist, album):\n",
    "    search_url = f\"https://musicbrainz.org/ws/2/release-group/?query=artist:{artist} AND release:{album}&fmt=json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(search_url, headers=HEADERS).json()\n",
    "        release_groups = response.get(\"release-groups\", [])\n",
    "\n",
    "        if not release_groups:\n",
    "            return None, None # Aucune donnée trouvée\n",
    "\n",
    "        mbid = response[\"release-groups\"][0][\"id\"]  # ID de l'album\n",
    "\n",
    "\n",
    "        # Récupérer l'image si disponible\n",
    "        image_url = f\"https://coverartarchive.org/release-group/{mbid}/front\"\n",
    "        mbid = response[\"release-groups\"][0][\"releases\"][0][\"id\"]  # ID de l'album\n",
    "\n",
    "        # Récupération du nombre de pistes\n",
    "        release_details_url = f\"https://musicbrainz.org/ws/2/release/{mbid}?inc=recordings&fmt=json\"\n",
    "        tracks_data = requests.get(release_details_url, headers=HEADERS).json()\n",
    "        nb_tracks = len(tracks_data[\"media\"][0][\"tracks\"]) if \"media\" in tracks_data else None\n",
    "\n",
    "        return image_url, nb_tracks\n",
    "    except (IndexError, KeyError, requests.RequestException):\n",
    "        return None, None  # En cas d'erreur, on renvoie None\n",
    "\n",
    "print(\"Beginning of data importing...\")\n",
    "\n",
    "# Exécuter la requête SPARQL\n",
    "data = execute_sparql_query()\n",
    "\n",
    "albums = {}\n",
    "\n",
    "img_folder = \"img\"\n",
    "# Supprimer le dossier s'il existe\n",
    "if os.path.exists(img_folder):\n",
    "    shutil.rmtree(img_folder)\n",
    "\n",
    "# Recréer un dossier vide\n",
    "os.makedirs(img_folder)\n",
    "\n",
    "for item in data[\"results\"][\"bindings\"]:\n",
    "    album_name = item.get(\"albumLabel\", {}).get(\"value\", \"Unknown Album\")\n",
    "    artist_name = item.get(\"bandLabel\", {}).get(\"value\", \"Unknown Artist\")\n",
    "    genre = item.get(\"genreLabel\", {}).get(\"value\", \"Unknown Genre\")\n",
    "    release_date = item.get(\"date\", {}).get(\"value\", \"Unknown Date\")\n",
    "    nb_tracks = item.get(\"nbTracks\", {}).get(\"value\", None)\n",
    "    image_url = item.get(\"image\", {}).get(\"value\", None)\n",
    "\n",
    "    # Si aucune image ou aucun nombre de pistes, on utilise MusicBrainz\n",
    "    if not image_url or not nb_tracks:\n",
    "        mb_image, mb_tracks = get_musicbrainz_data(artist_name, album_name)\n",
    "        image_url = image_url or mb_image  # Priorité à Wikidata, sinon MusicBrainz\n",
    "        nb_tracks = nb_tracks or mb_tracks  # Priorité à Wikidata, sinon MusicBrainz\n",
    "\n",
    "    # Si toujours pas d'image, on ignore cet album\n",
    "    if not image_url:\n",
    "        continue\n",
    "\n",
    "    image_filename = f\"img/{album_name.replace(' ', '_')}.jpg\"\n",
    "    filename, exif = download_image(image_url, image_filename)\n",
    "\n",
    "    # Ajouter à la liste\n",
    "    albums[image_filename] ={\n",
    "        \"album\": album_name,\n",
    "        \"artist\": artist_name,\n",
    "        \"genre\": genre,\n",
    "        \"release_date\": release_date,\n",
    "        \"tracks\": nb_tracks if nb_tracks else \"Unknown\",\n",
    "        \"image\": image_filename,\n",
    "        \"img_exif\": exif or {\"Favorite\": \"NotFavorite\", \"DominantColor1\": \"Undefined\"}\n",
    "    }\n",
    "    sleep(1)\n",
    "\n",
    "\n",
    "# Sauvegarde des résultats en JSON\n",
    "with open(\"albums.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(albums, f, indent=4)\n",
    "\n",
    "print(\"All data had been imported.\")\n",
    "print(f\"{len(albums)} albums traités et sauvegardés.\")\n",
    "\n",
    "print(\"Dominant color begin ...\")\n",
    "\n",
    "def simplify_color(rgb):\n",
    "    r, g, b = rgb\n",
    "    max_val = max(r, g, b)\n",
    "    if max_val == r:\n",
    "        return 'red'\n",
    "    elif max_val == g:\n",
    "        return 'green'\n",
    "    elif max_val == b:\n",
    "        return 'blue'\n",
    "    return 'Other'\n",
    "\n",
    "# Dominant color\n",
    "n = 1  # How many dominant color we want\n",
    "default_color = (255)\n",
    "image_folder = \"./img/\"\n",
    "image_files = os.listdir(image_folder)\n",
    "json_file = \"./albums.json\"\n",
    "\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    if image_file.endswith(('.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert(\"RGB\")\n",
    "        np_img = np.array(img)\n",
    "\n",
    "        numarray = np.array(img.getdata(), np.uint8)\n",
    "        clusters = KMeans(n_clusters=n, n_init=2)\n",
    "        clusters.fit(numarray)\n",
    "        cluster_centers = clusters.cluster_centers_\n",
    "        colors_list = [tuple(map(int, cluster_centers[i])) for i in range(n)]\n",
    "\n",
    "        simplified_colors_list = [simplify_color(color) for color in colors_list]  # Simplify colors\n",
    "\n",
    "        # Update the JSON data part as below\n",
    "        with open(json_file, 'r+') as f:\n",
    "            data = json.load(f)\n",
    "            img_key = f\"img/{image_file}\"\n",
    "            if data[img_key]:\n",
    "                for i, color in enumerate(simplified_colors_list, start=1):\n",
    "                    data[img_key][\"img_exif\"][f\"Favorite\"] = \"NotFavorite\"\n",
    "                    data[img_key][\"img_exif\"][f\"DominantColor{i}\"] = color\n",
    "                f.seek(0)\n",
    "                json.dump(data, f, indent=4)\n",
    "                f.truncate()\n",
    "\n",
    "\n",
    "print(\"Dominant color done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Étiquetage et annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252cf510352e44d9b67a80d93da15bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Charger les données depuis albums.json\n",
    "with open(\"albums.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    albums_data = json.load(f)\n",
    "\n",
    "# Fonction pour récupérer 20 albums aléatoires\n",
    "def get_random_albums(num=20):\n",
    "    return random.sample(list(albums_data.values()), min(num, len(albums_data)))\n",
    "\n",
    "# Fonction pour afficher un album\n",
    "def display_album(album_info):\n",
    "    # Charger l'image si disponible\n",
    "    image_path = album_info[\"image\"]\n",
    "    if os.path.exists(image_path):\n",
    "        img = Image.open(image_path)\n",
    "    else:\n",
    "        img = None\n",
    "\n",
    "    # Création des widgets\n",
    "    album_label = widgets.HTML(f\"<b>{album_info['album']}</b>\")\n",
    "    artist_label = widgets.HTML(f\"Artist: {album_info['artist']}\")\n",
    "    genre_label = widgets.HTML(f\"Genre: {album_info['genre']}\")\n",
    "    year_label = widgets.HTML(f\"Year: {album_info['release_date'][:4]}\")\n",
    "    \n",
    "    image_widget = widgets.Image(value=open(image_path, \"rb\").read(), format='jpg', width=100, height=100) if img else widgets.Label(\"No Image\")\n",
    "    \n",
    "    # Mise en page\n",
    "    album_box = widgets.HBox([\n",
    "        image_widget,\n",
    "        widgets.VBox([album_label, artist_label, genre_label, year_label])\n",
    "    ])\n",
    "    \n",
    "    return album_box\n",
    "\n",
    "# Fonction pour afficher l'interface\n",
    "def show_albums():\n",
    "    albums = get_random_albums(20)\n",
    "    album_widgets = [display_album(album) for album in albums]\n",
    "    display(widgets.VBox(album_widgets))\n",
    "\n",
    "# Afficher les albums\n",
    "show_albums()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
